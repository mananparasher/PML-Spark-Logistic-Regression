{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "spark = SparkSession.builder.appName(\"Logistic Regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_IN.\n",
      "Warning: Failed to set locale category LC_TIME to en_IN.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_IN.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_IN.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_IN.\n",
      "--2020-06-20 10:02:46--  https://raw.githubusercontent.com/mananparasher/Spark-Datasets/master/breast_cancer.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.124.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.124.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 119888 (117K) [text/plain]\n",
      "Saving to: ‘breast_cancer.csv’\n",
      "\n",
      "breast_cancer.csv   100%[===================>] 117.08K   413KB/s    in 0.3s    \n",
      "\n",
      "2020-06-20 10:02:47 (413 KB/s) - ‘breast_cancer.csv’ saved [119888/119888]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mananparasher/Spark-Datasets/master/breast_cancer.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data in Spark DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+------+-------+-------+------+-------+------+-------+------+------+-----+-----+--------+-------+-------+-------+-------+--------+-----+-----+-----+------+------+------+------+------+------+-------+----+\n",
      "|  _c0|  _c1|  _c2|   _c3|    _c4|    _c5|   _c6|    _c7|   _c8|    _c9|  _c10|  _c11| _c12| _c13|    _c14|   _c15|   _c16|   _c17|   _c18|    _c19| _c20| _c21| _c22|  _c23|  _c24|  _c25|  _c26|  _c27|  _c28|   _c29|_c30|\n",
      "+-----+-----+-----+------+-------+-------+------+-------+------+-------+------+------+-----+-----+--------+-------+-------+-------+-------+--------+-----+-----+-----+------+------+------+------+------+------+-------+----+\n",
      "|17.99|10.38|122.8|1001.0| 0.1184| 0.2776|0.3001| 0.1471|0.2419|0.07871| 1.095|0.9053|8.589|153.4|0.006399|0.04904|0.05373|0.01587|0.03003|0.006193|25.38|17.33|184.6|2019.0|0.1622|0.6656|0.7119|0.2654|0.4601| 0.1189|   0|\n",
      "|20.57|17.77|132.9|1326.0|0.08474|0.07864|0.0869|0.07017|0.1812|0.05667|0.5435|0.7339|3.398|74.08|0.005225|0.01308| 0.0186| 0.0134|0.01389|0.003532|24.99|23.41|158.8|1956.0|0.1238|0.1866|0.2416| 0.186| 0.275|0.08902|   0|\n",
      "|19.69|21.25|130.0|1203.0| 0.1096| 0.1599|0.1974| 0.1279|0.2069|0.05999|0.7456|0.7869|4.585|94.03| 0.00615|0.04006|0.03832|0.02058| 0.0225|0.004571|23.57|25.53|152.5|1709.0|0.1444|0.4245|0.4504| 0.243|0.3613|0.08758|   0|\n",
      "|11.42|20.38|77.58| 386.1| 0.1425| 0.2839|0.2414| 0.1052|0.2597|0.09744|0.4956| 1.156|3.445|27.23| 0.00911|0.07458|0.05661|0.01867|0.05963|0.009208|14.91| 26.5|98.87| 567.7|0.2098|0.8663|0.6869|0.2575|0.6638|  0.173|   0|\n",
      "|20.29|14.34|135.1|1297.0| 0.1003| 0.1328| 0.198| 0.1043|0.1809|0.05883|0.7572|0.7813|5.438|94.44| 0.01149|0.02461|0.05688|0.01885|0.01756|0.005115|22.54|16.67|152.2|1575.0|0.1374| 0.205|   0.4|0.1625|0.2364|0.07678|   0|\n",
      "+-----+-----+-----+------+-------+-------+------+-------+------+-------+------+------+-----+-----+--------+-------+-------+-------+-------+--------+-----+-----+-----+------+------+------+------+------+------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv').options(header='false',inferschema='true').load('breast_cancer.csv')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[_c0: double, _c1: double, _c2: double, _c3: double, _c4: double, _c5: double, _c6: double, _c7: double, _c8: double, _c9: double, _c10: double, _c11: double, _c12: double, _c13: double, _c14: double, _c15: double, _c16: double, _c17: double, _c18: double, _c19: double, _c20: double, _c21: double, _c22: double, _c23: double, _c24: double, _c25: double, _c26: double, _c27: double, _c28: double, _c29: double, _c30: int]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|_c30|\n",
      "+--------------------+----+\n",
      "|[17.99,17.99,17.9...|   0|\n",
      "|[20.57,20.57,20.5...|   0|\n",
      "|[19.69,19.69,19.6...|   0|\n",
      "|[11.42,11.42,11.4...|   0|\n",
      "|[20.29,20.29,20.2...|   0|\n",
      "|[12.45,12.45,12.4...|   0|\n",
      "|[18.25,18.25,18.2...|   0|\n",
      "|[13.71,13.71,13.7...|   0|\n",
      "|[13.0,13.0,13.0,5...|   0|\n",
      "|[12.46,12.46,12.4...|   0|\n",
      "|[16.02,16.02,16.0...|   0|\n",
      "|[15.78,15.78,15.7...|   0|\n",
      "|[19.17,19.17,19.1...|   0|\n",
      "|[15.85,15.85,15.8...|   0|\n",
      "|[13.73,13.73,13.7...|   0|\n",
      "|[14.54,14.54,14.5...|   0|\n",
      "|[14.68,14.68,14.6...|   0|\n",
      "|[16.13,16.13,16.1...|   0|\n",
      "|[19.81,19.81,19.8...|   0|\n",
      "|[13.54,13.54,13.5...|   1|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['_c0', '_c0', '_c0', '_c3', '_c4', '_c5', '_c6', '_c7', \\\n",
    "'_c8', '_c9', '_c10', '_c12', '_c13','_c14','_c14','_c16','_c17','_c18','_c19','_c20','_c21','_c22'\\\n",
    ",'_c23','_c24','_c25','_c26','_c27','_c28','_c29'], outputCol = 'features')\n",
    "\n",
    "transformed_df = vectorAssembler.transform(df)\n",
    "transformed_df.select([\"features\",\"_c30\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|     Scaled_features|_c30|\n",
      "+--------------------+----+\n",
      "|[5.10492359418783...|   0|\n",
      "+--------------------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"Scaled_features\")\n",
    "scaled_df=standardscaler.fit(transformed_df).transform(transformed_df)\n",
    "scaled_df.select(\"Scaled_features\",\"_c30\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=scaled_df.select(['Scaled_features','_c30'])\n",
    "splitting_df = final_df.randomSplit([0.8, 0.2])\n",
    "training_df = splitting_df[0]\n",
    "testing_df = splitting_df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Fitting the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression_41b7a47e1e97d3dfcb26"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticregression = LogisticRegression\\\n",
    "(featuresCol = 'Scaled_features', labelCol='_c30', maxIter=20)\n",
    "\n",
    "model = logisticregression.fit(training_df)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using the Trained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------------+\n",
      "|prediction|_c30|     Scaled_features|\n",
      "+----------+----+--------------------+\n",
      "|       1.0|   1|[2.47612914301740...|\n",
      "|       1.0|   1|[2.53969239399561...|\n",
      "|       1.0|   1|[2.64837420258783...|\n",
      "|       1.0|   1|[2.66653513143875...|\n",
      "|       1.0|   1|[2.71477509869900...|\n",
      "|       1.0|   1|[2.75819106923322...|\n",
      "|       1.0|   1|[2.76329883047254...|\n",
      "|       1.0|   1|[2.80245833330734...|\n",
      "|       1.0|   1|[2.88588510021624...|\n",
      "|       1.0|   1|[2.99939090553448...|\n",
      "+----------+----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(testing_df)\n",
    "prediction.select(\"prediction\",\"_c30\",\"Scaled_features\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
